#!/bin/bash

# 2019-12-24, ma duo.

# main refrence:kaldi/egs/swbd/s5c/local/run_asr_segmentation.sh

# # This script demonstrates nnet3-based speech activity detection for
# segmentation.
# This script:
# 0) Prepares a normal gmm-hmm triphone system
# 1) Prepares targets (per-frame labels) for a subset of training data 
#    using GMM models
# 2) Augments the training data with reverberation and additive noise
# 3) Trains TDNN+Stats or TDNN+LSTM neural network using the targets 
#    and augmented data
# 4) Demonstrates using the SAD system to get segments of eval data and decode

# All experiments are in seame set


. path.sh
. cmd.sh
cmd="slurm.pl  --quiet --exclude=node06,node07"
steps=
nj=40
tgtdir=run_1a
exp_root=$tgtdir/exp
. utils/parse_options.sh || exit 1


steps=$(echo $steps | perl -e '$steps=<STDIN>;  $has_format = 0;
  if($steps =~ m:(\d+)\-$:g){$start = $1; $end = $start + 10; $has_format ++;}
        elsif($steps =~ m:(\d+)\-(\d+):g) { $start = $1; $end = $2; if($start == $end){}elsif($start < $end){ $end = $2 +1;}else{die;} $has_format ++; }
      if($has_format > 0){$steps=$start;  for($i=$start+1; $i < $end; $i++){$steps .=":$i"; }} print $steps;' 2>/dev/null)  || exit 1

if [ ! -z "$steps" ]; then
  for x in $(echo $steps|sed 's/[,:]/ /g'); do
    index=$(printf "%02d" $x);
    declare step$index=1
  done
fi



original_src=/home4/md510/w2018/data/seame
dict=data/dict
lang=data/lang  #  It is generated by supervised data.

# 1. copy data
if [ ! -z $step01 ]; then
   datadir=`pwd`/data
   mkdir -p ${datadir}
   for name in dict dev_man dev_sge train; do
    cp -r   $original_src/${name} $datadir || exit 1;
   done
fi

# 2. make lang
if [ ! -z $step02 ]; then
  utils/validate_dict_dir.pl $dict || { echo "## ERROR (step01): failed to validating dict '$dict'" && exit 1;  }
  utils/prepare_lang.sh $dict "<unk>" $lang/tmp $lang
fi


# 3. make mfcc
mfccdir=`pwd`/mfcc
if [ ! -z $step03 ];then
  for sdata in train dev_man dev_sge; do
    steps/make_mfcc.sh --cmd "$cmd" --nj $nj \
      --mfcc-config conf/mfcc.conf  --write-utt2num-frames false data/${sdata} exp/make_mfcc/${sdata} $mfccdir || exit 1;
    steps/compute_cmvn_stats.sh data/${sdata} exp/make_mfcc/${sdata} $mfccdir || exit 1;
    #This script will fix sorting errors and will remove any utterances for which some required data, such as feature data or transcripts, is missing.
    utils/fix_data_dir.sh data/${sdata}
    echo "## LOG : done with mfcc-pitch feat"

  done
fi



###############################################################################
# Prepare  subsets for initial GMM training
###############################################################################

if [ ! -z $step04 ]; then
  #utils/subset_data_dir.sh --shortest data/train_sup 100000 data/train_sup_100kshort
  utils/subset_data_dir.sh  data/train 10000 data/train_10k
  utils/data/remove_dup_utts.sh 100 data/train_10k data/train_10k_nodup

fi

###############################################################################
# pepared  lang_test 
# why selet maxent 3-gram ,
# more detail ,you can read /home4/md510/w2019a/kaldi-recipe/lm/data/lm/perplexities.txt
#                           /home4/md510/w2019a/kaldi-recipe/lm/data/lm/ 
#                           /home4/md510/w2019a/kaldi-recipe/lm/train_lms_srilm.sh 

###############################################################################
lmdir=data/local/lm
train_data=data/train
dictdir=data/dict
# prepared G.fst
[ -d $lmdir ] || mkdir -p $lmdir
oov_symbol="<UNK>"
words_file=data/lang/words.txt
if [ ! -z $step05 ]; then
   echo "Using words file: $words_file"
   sort $words_file | awk '{print $1}' | grep -v '\#0' | grep -v '<eps>' | grep -v -F "$oov_symbol" > $lmdir/vocab
   cat $train_data/text | cut -f2- -d' ' > $lmdir/train.txt
fi
if [ ! -z $step06 ]; then
  echo "-------------------"
  echo "Maxent 3grams"
  echo "-------------------"
  # sed 's/'${oov_symbol}'/<unk>/g' means: using <unk> to replace ${oov_symbol}
  sed 's/'${oov_symbol}'/<unk>/g' $lmdir/train.txt | \
    ngram-count -lm - -order 3 -text - -vocab $lmdir/vocab -unk -sort -maxent -maxent-convert-to-arpa|\
    sed 's/<unk>/'${oov_symbol}'/g' | gzip -c > $lmdir/3gram.me.gz || exit 1
  echo "## LOG (step06): done with '$lmdir/3gram.me.gz' "
fi
lang_test=data/local/lang_test
[ -d $lang_test ] || mkdir -p $lang_test
if [ ! -z $step07 ]; then
  utils/format_lm.sh data/lang data/local/lm/3gram.me.gz \
    $dictdir/lexiconp.txt $lang_test
  utils/validate_lang.pl $lang_test
  echo "## LOG (step07): done with '$lang_test'"
fi

# gmm-hmm system refrence:https://github.com/kaldi-asr/kaldi/blob/master/egs/swbd/s5c/run.sh
# 
###############################################################################
# GMM system training using  seame supervised data
###############################################################################
src_dev_man=data/dev_man
src_dev_sge=data/dev_sge
#because in decoding process,according to the number of speakers, split tasks are performed. 
dev_man_nj=$(wc -l $src_dev_man/spk2utt | awk '{print $1}' || exit 1;)
dev_sge_nj=$(wc -l $src_dev_sge/spk2utt | awk '{print $1}' || exit 1;)

if [ ! -z $step08 ]; then
  steps/train_mono.sh --nj  $nj  --cmd "$cmd" \
    data/train_10k_nodup $lang $exp_root/mono || exit 1
fi

if [ ! -z $step09 ]; then
  steps/align_si.sh --nj $nj --cmd "$cmd" \
    data/train $lang $exp_root/mono $exp_root/mono_ali || exit 1

  steps/train_deltas.sh --cmd "$cmd" \
    2500 20000 data/train $lang $exp_root/mono_ali $exp_root/tri1 || exit 1

fi

if [ ! -z $step10 ]; then
  steps/align_si.sh --nj $nj --cmd "$train_cmd" \
            data/train  $lang $exp_root/tri1 $exp_root/tri1_ali

  steps/train_deltas.sh --cmd "$train_cmd" \
   3200 30000 data/train $lang $exp_root/tri1_ali $exp_root/tri2

fi

if [ ! -z $step11 ]; then
  steps/align_si.sh --nj $nj --cmd "$cmd" \
    data/train $lang $exp_root/tri2 $exp_root/tri2_ali || exit 1;

  steps/train_lda_mllt.sh --cmd "$cmd" \
     --splice-opts "--left-context=3 --right-context=3" \
     5000 40000 data/train $lang $exp_root/tri2_ali $exp_root/tri3 || exit 1;
fi

if [ ! -z $step12 ]; then
  steps/align_fmllr.sh --nj $nj --cmd "$cmd" \
    data/train $lang $exp_root/tri3 $exp_root/tri3_ali || exit 1;

  steps/train_sat.sh --cmd "$cmd" \
    5000 100000 data/train $lang $exp_root/tri3_ali $exp_root/tri4 || exit 1;
fi

if [ ! -z $step13 ];then
   utils/mkgraph.sh $lang_test $exp_root/tri4 $exp_root/tri4/graph  || exit 1;
    steps/decode_fmllr.sh --nj ${dev_man_nj} --cmd "$cmd" --config conf/decode.config \
     $exp_root/tri4/graph data/dev_man $exp_root/tri4/decode_dev_man  || exit 1;
     steps/decode_fmllr.sh --nj ${dev_man_nj} --cmd "$cmd" --config conf/decode.config \
     $exp_root/tri4/graph data/dev_sge $exp_root/tri4/decode_dev_sge   || exit 1;
 #               
 # WER on dev_sge  49.04 
 # WER on dev_man  37.31 

fi

# refrence:kaldi/egs/swbd/s5c/local/run_asr_segmentation.sh
if [ ! -z $step14 ];then
  source-md/egs/speech_activity_detection_using_nnet3/run_asr_segmentation_swbd_5c.sh \
   --steps 1-7 \
   --exp-root $exp_root \
   --lang data/lang \
   --lang-test data/local/lang_test \
   --data-dir data/train \
   --sat-model-dir $exp_root/tri4 \
   --model-dir $exp_root/tri3

fi

# now I use the other method, (e.g:train_lstm_asr_sad_1a.sh)
if [ ! -z $step15 ];then
    source-md/egs/speech_activity_detection_using_nnet3/run_asr_segmentation_babel_5d.sh \
     --steps 6-9 \
     --affix "_1b" \
     --exp-root $exp_root \
     --lang data/lang \
     --lang-test data/local/lang_test \
     --data-dir data/train \
     --sat-model-dir $exp_root/tri4 \
     --model-dir $exp_root/tri3

fi
